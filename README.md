# IsCoolGPT Backend

![CI/CD](https://github.com/mariajuliapessoa/iscoolgpt/actions/workflows/ci-cd.yml/badge.svg)

Assistente educacional inteligente desenvolvido com Flask e integra√ß√£o com Google Gemini AI. O sistema permite que alunos fa√ßam perguntas e recebam respostas did√°ticas personalizadas atrav√©s de uma API RESTful.

## √çndice

- [Tecnologias](#-tecnologias)
- [Funcionalidades](#-funcionalidades)
- [Pr√©-requisitos](#-pr√©-requisitos)
- [Instala√ß√£o](#-instala√ß√£o)
- [Configura√ß√£o](#-configura√ß√£o)
- [Como Executar](#-como-executar)
- [Endpoints da API](#-endpoints-da-api)
- [Testando a API](#-testando-a-api)
- [Docker](#-docker)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Seguran√ßa](#-seguran√ßa)
- [Logs](#-logs)
- [Autora](#-autora)

## Tecnologias

Este projeto foi desenvolvido com as seguintes tecnologias:

- **Python 3.11** - Linguagem de programa√ß√£o
- **Flask 3.0+** - Framework web minimalista
- **Google Generative AI (Gemini 2.5)** - Modelo de linguagem para respostas inteligentes
- **Docker** - Containeriza√ß√£o da aplica√ß√£o
- **Git/GitHub** - Controle de vers√£o

### Bibliotecas Python utilizadas:
- `flask` - Framework web
- `google-generativeai` - Cliente da API Gemini
- `python-dotenv` - Gerenciamento de vari√°veis de ambiente

## Funcionalidades

- API RESTful para assistente educacional
- Integra√ß√£o com LLM (Google Gemini 2.5-flash)
- Sistema de logs autom√°tico de todas as requisi√ß√µes
- Arquitetura modular com Blueprints (Flask)
- Dockeriza√ß√£o completa
- Respostas contextualizadas e did√°ticas
- Tratamento de erros robusto

## Pr√©-requisitos

Antes de come√ßar, voc√™ precisa ter instalado em sua m√°quina:

### Obrigat√≥rios:
- **Python 3.10 ou superior** - [Download Python](https://www.python.org/downloads/)
- **Git** - [Download Git](https://git-scm.com/downloads)
- **Conta Google** - Para obter API Key do Gemini

### Opcionais (mas recomendados):
- **Docker Desktop** - [Download Docker](https://www.docker.com/products/docker-desktop) (para executar em container)
- **VS Code** - [Download VS Code](https://code.visualstudio.com/) (editor de c√≥digo)
- **Thunder Client** (extens√£o do VS Code) ou **Postman** - Para testar a API

### Obter API Key do Google Gemini:
1. Acesse: [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Fa√ßa login com sua conta Google
3. Clique em "Create API Key"
4. Copie a chave gerada (formato: `AIzaSy...`)
5. Guarde em local seguro

## üîß Instala√ß√£o

### 1. Clone o reposit√≥rio

git clone https://github.com/mariajuliapessoa/iscoolgpt.git
cd iscoolgpt

text

### 2. Crie e ative o ambiente virtual

**Windows (PowerShell):**
python -m venv venv
.\venv\Scripts\Activate

text

**Linux/Mac:**
python3 -m venv venv
source venv/bin/activate

text

### 3. Instale as depend√™ncias

pip install -r requirements.txt

text

Pacotes que ser√£o instalados:
- Flask
- google-generativeai
- python-dotenv

## ‚öôÔ∏è Configura√ß√£o

### 1. Crie o arquivo de vari√°veis de ambiente

Crie um arquivo `.env` na raiz do projeto:

Windows
type nul > .env

Linux/Mac
touch .env

text

### 2. Configure a API Key

Abra o arquivo `.env` e adicione:

GEMINI_API_KEY=sua-chave-aqui

text

** IMPORTANTE:** Substitua `sua-chave-aqui` pela sua chave real do Google Gemini.

**Exemplo:**
GEMINI_API_KEY=AIzaSyBCEh1234567890abcdefghijklmnopqrs

text

### 3. Verificar configura√ß√£o

O arquivo `.env` **n√£o** deve ser commitado no Git. Verifique se est√° no `.gitignore`:

cat .gitignore | findstr .env # Windows
grep .env .gitignore # Linux/Mac

text

## Como Executar

### Modo desenvolvimento (local)

1. Certifique-se de que o ambiente virtual est√° ativo
2. Execute:

python app.py

text

3. A aplica√ß√£o estar√° rodando em: `http://localhost:5000`

Voc√™ ver√° no terminal:
Serving Flask app 'app'

Debug mode: on

Running on http://127.0.0.1:5000

text

### Parar a aplica√ß√£o

Pressione `Ctrl + C` no terminal

## üì° Endpoints da API

### 1. `GET /`
Rota de boas-vindas

**Exemplo de requisi√ß√£o:**
GET http://localhost:5000/

text

**Resposta:**
{
"message": "Bem-vindo ao iscoolgpt-backend!"
}

text

---

### 2. `GET /api/conteudos`
Lista conte√∫dos educacionais dispon√≠veis

**Exemplo de requisi√ß√£o:**
GET http://localhost:5000/api/conteudos

text

**Resposta:**
[
{
"id": 1,
"titulo": "Fun√ß√µes em Python"
},
{
"id": 2,
"titulo": "Estruturas de Dados"
}
]

text

---

### 3. `POST /api/pergunta`
Envia uma pergunta para o assistente educacional com IA

**Exemplo de requisi√ß√£o:**
POST http://localhost:5000/api/pergunta
Content-Type: application/json

{
"texto": "O que √© uma fun√ß√£o em Python?"
}

text

**Resposta:**
{
"pergunta": "O que √© uma fun√ß√£o em Python?",
"resposta": "Uma fun√ß√£o em Python √© um bloco de c√≥digo reutiliz√°vel que executa uma tarefa espec√≠fica. Ela √© definida usando a palavra-chave 'def', seguida do nome da fun√ß√£o e par√™nteses. As fun√ß√µes ajudam a organizar o c√≥digo, tornam-no mais leg√≠vel e facilitam a reutiliza√ß√£o."
}

text

**Poss√≠veis erros:**

- **400 Bad Request** - Pergunta vazia
{
"erro": "Pergunta vazia"
}

text

- **500 Internal Server Error** - Erro ao processar com a LLM
{
"erro": "Erro ao processar: [detalhes do erro]"
}

text

## Testando a API

### Op√ß√£o 1: Thunder Client (VS Code)

1. Instale a extens√£o **Thunder Client** no VS Code
2. Clique no √≠cone do raio (‚ö°) na barra lateral
3. Clique em **"New Request"**
4. Configure a requisi√ß√£o:

**Para GET /api/conteudos:**
- M√©todo: `GET`
- URL: `http://localhost:5000/api/conteudos`
- Clique em **Send**

**Para POST /api/pergunta:**
- M√©todo: `POST`
- URL: `http://localhost:5000/api/pergunta`
- Aba **Body** ‚Üí Selecione **JSON**
- Cole:
{
"texto": "O que √© Docker?"
}

text
- Clique em **Send**

### Op√ß√£o 2: Postman

1. Baixe e instale: [Postman](https://www.postman.com/downloads/)
2. Crie uma nova requisi√ß√£o
3. Configure conforme os exemplos acima
4. Clique em **Send**

### Op√ß√£o 3: cURL (Terminal)

**GET /api/conteudos:**
curl http://localhost:5000/api/conteudos

text

**POST /api/pergunta:**

**Windows (PowerShell):**
Invoke-RestMethod -Uri http://localhost:5000/api/pergunta -Method POST -ContentType "application/json" -Body '{"texto": "O que √© Python?"}'

text

**Linux/Mac:**
curl -X POST http://localhost:5000/api/pergunta
-H "Content-Type: application/json"
-d '{"texto": "O que √© Python?"}'

text

### Op√ß√£o 4: Navegador (apenas GET)

Acesse diretamente no navegador:
- `http://localhost:5000/`
- `http://localhost:5000/api/conteudos`

## Docker

### Pr√©-requisitos
- Docker Desktop instalado e rodando

### Build da imagem

docker build -t iscoolgpt-backend .

text

Isso pode levar alguns minutos na primeira vez.

### Executar o container

docker run -p 5000:5000 --env-file .env iscoolgpt-backend

text

**Par√¢metros:**
- `-p 5000:5000` - Mapeia a porta 5000 do container para a porta 5000 do host
- `--env-file .env` - Carrega vari√°veis de ambiente do arquivo `.env`
- `iscoolgpt-backend` - Nome da imagem

### Executar em background (detached)

docker run -d -p 5000:5000 --env-file .env --name iscoolgpt iscoolgpt-backend

text

### Comandos √∫teis do Docker

Listar containers rodando
docker ps

Ver logs do container
docker logs iscoolgpt

Parar container
docker stop iscoolgpt

Remover container
docker rm iscoolgpt

Listar imagens
docker images

Remover imagem
docker rmi iscoolgpt-backend

text

## Estrutura do Projeto

iscoolgpt-backend/
‚îÇ
‚îú‚îÄ‚îÄ routes/ # M√≥dulo de rotas (Blueprints)
‚îÇ ‚îú‚îÄ‚îÄ init.py # Inicializa o pacote routes
‚îÇ ‚îú‚îÄ‚îÄ conteudos.py # Endpoints relacionados a conte√∫dos
‚îÇ ‚îî‚îÄ‚îÄ perguntas.py # Endpoints do assistente (integra√ß√£o LLM)
‚îÇ
‚îú‚îÄ‚îÄ app.py # Aplica√ß√£o principal Flask
‚îú‚îÄ‚îÄ requirements.txt # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ Dockerfile # Configura√ß√£o para containeriza√ß√£o
‚îú‚îÄ‚îÄ .dockerignore # Arquivos ignorados pelo Docker
‚îú‚îÄ‚îÄ .gitignore # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ .env # Vari√°veis de ambiente (N√ÉO COMMITAR)
‚îú‚îÄ‚îÄ request_logs.txt # Logs autom√°ticos de requisi√ß√µes
‚îî‚îÄ‚îÄ README.md # Documenta√ß√£o do projeto

text

### Descri√ß√£o dos arquivos principais:

- **app.py**: Ponto de entrada da aplica√ß√£o. Configura Flask, registra Blueprints e middleware de logging.
- **routes/conteudos.py**: Define endpoint GET para listar conte√∫dos educacionais.
- **routes/perguntas.py**: Define endpoint POST para enviar perguntas ao assistente com IA (Gemini).
- **requirements.txt**: Lista todas as depend√™ncias Python necess√°rias.
- **Dockerfile**: Define como construir a imagem Docker da aplica√ß√£o.
- **.env**: Armazena vari√°veis sens√≠veis (API keys). **Nunca** deve ser commitado.

## Seguran√ßa

### Boas pr√°ticas implementadas:

‚úÖ **Vari√°veis de ambiente**: API keys armazenadas em `.env`, n√£o no c√≥digo  
‚úÖ **`.gitignore`**: Impede commit de arquivos sens√≠veis (`.env`, `venv/`, logs)  
‚úÖ **`.dockerignore`**: N√£o inclui arquivos desnecess√°rios na imagem Docker  
‚úÖ **Tratamento de erros**: Mensagens gen√©ricas para o usu√°rio, logs detalhados  
‚úÖ **Logs de auditoria**: Todas as requisi√ß√µes s√£o registradas  

### Avisos importantes:

- **Nunca** compartilhe seu arquivo `.env` ou API key
- **Nunca** commite o `.env` no Git
- Em produ√ß√£o, use servi√ßos como **AWS Secrets Manager** ou **Azure Key Vault**
- Desative `debug=True` em produ√ß√£o

## Logs

A aplica√ß√£o gera logs autom√°ticos de todas as requisi√ß√µes em `request_logs.txt`.

### Formato do log:

{
"timestamp": "2025-11-18 09:00:00.123456",
"method": "POST",
"endpoint": "/api/pergunta",
"query_params": {},
"body": {"texto": "O que √© Python?"},
"ip": "127.0.0.1"
}

text

### Visualizar logs:

Ver √∫ltimas 10 linhas
tail -n 10 request_logs.txt # Linux/Mac
Get-Content request_logs.txt -Tail 10 # Windows PowerShell

Ver em tempo real
tail -f request_logs.txt # Linux/Mac
Get-Content request_logs.txt -Wait # Windows PowerShell

text

## Autora

**Maria Julia Pessoa**

- GitHub: [@mariajuliapessoa](https://github.com/mariajuliapessoa)
- Projeto: Trabalho Final - Cloud Computing 25.2
- Institui√ß√£o: CESAR School

## üìÑ Licen√ßa

Este projeto foi desenvolvido para fins educacionais como parte da cadeira de Cloud Computing